# ğŸ›¡ï¸ GuardRAG - Secure Document RAG System

Ein fortschrittliches RAG-System (Retrieval-Augmented Generation) auf Basis von COLPALI mit integrierten Guardrails fÃ¼r sichere und vertrauenswÃ¼rdige Dokumentenverarbeitung.

## ğŸ¯ Ãœberblick

GuardRAG kombiniert modernste Vision-Language-Modelle (COLPALI) mit umfassenden Sicherheitsmechanismen (Guardrails), um eine robuste und vertrauenswÃ¼rdige LÃ¶sung fÃ¼r die Analyse wissenschaftlicher Dokumente zu bieten.

### âœ¨ Kernfunktionen

- **ğŸ” COLPALI-Integration**: Effiziente visuelle Dokumentenretrieval mit dem `vidore/colqwen2.5-v0.2` Modell
- **ğŸ›¡ï¸ Input Guardrails**: Validierung und Filterung eingehender Anfragen
- **âœ… Output Guardrails**: ÃœberprÃ¼fung generierter Antworten auf Faktentreue und Sicherheit
- **ğŸ“ File Upload**: UnterstÃ¼tzung fÃ¼r PDF, DOCX, TXT, MD, HTML-Dateien
- **ğŸš€ FastAPI-Interface**: RESTful API mit automatischer Dokumentation
- **ğŸ§  Hybrid LLM+Regex**: Intelligente Content-Validierung mit automatischem Lernen
- **ğŸ”’ PII-Schutz**: Erkennung und Sanitisierung persÃ¶nlicher Daten

## ğŸ—ï¸ Systemarchitektur

```
Benutzeranfrage
    â†“
[ Input Guardrail ] â”€â”€â”€ ğŸ” Hybrid LLM+Regex PrÃ¼fung:
    â”‚                   â€¢ ProfanitÃ¤t & ToxizitÃ¤t
    â”‚                   â€¢ PII-Erkennung (E-Mail, Tel, IBAN)
    â”‚                   â€¢ GefÃ¤hrliche Inhalte (Drogen, Waffen, Sprengstoff)
    â”‚                   â€¢ Konkurrenten-ErwÃ¤hnungen
    â”‚                   â€¢ Automatisches Lernen neuer Bedrohungen
    â†“ (ZUGELASSEN)
[ COLPALI Retrieval ] â”€â”€ ğŸ“Š Visuelle Dokumentensuche:
    â”‚                   â€¢ Layout-bewusste Analyse
    â”‚                   â€¢ OCR-freie Texterkennung
    â”‚                   â€¢ Multimodale Embeddings
    â†“
[ LLM Generation ] â”€â”€â”€â”€â”€â”€ ğŸ¤– Antwortgenerierung basierend auf Quellen
    â†“
[ Output Guardrail ] â”€â”€â”€ âœ… QualitÃ¤tsprÃ¼fung:
    â”‚                   â€¢ Faktentreue-Abgleich
    â”‚                   â€¢ Halluzinations-Detektion
    â”‚                   â€¢ SicherheitsprÃ¼fung
    â†“ (GÃœLTIG)
Sichere Antwort an Nutzer
```

## ğŸš€ Installation & Quick Start

### Voraussetzungen

- Python 3.10+
- [uv](https://docs.astral.sh/uv/) Paketmanager (empfohlen)
- [Ollama](https://ollama.com/) fÃ¼r lokale LLM-Inferenz
- GPU mit CUDA-UnterstÃ¼tzung (empfohlen)
- Docker (optional, fÃ¼r Services)

### 1. Repository klonen

```bash
git clone <repository-url>
cd GuardRAG
```

### 2. AbhÃ¤ngigkeiten installieren

```powershell
# Mit uv (empfohlen)
uv sync

# Oder mit pip
.venv\Scripts\activate
pip install -e .
```

### 3. Umgebung konfigurieren

Kopiere `.env.example` zu `.env` und passe die Werte an:

```bash
# LLM Configuration (Ollama)
LLM_ENDPOINT=http://localhost:11434/v1
LLM_API_KEY=ollama
LLM_MODEL=qwen2.5:latest

# COLPALI Configuration
COLPALI_MODEL=vidore/colqwen2.5-v0.2

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Guardrails Configuration
ENABLE_INPUT_GUARDRAILS=true
ENABLE_OUTPUT_GUARDRAILS=true
TOXICITY_THRESHOLD=0.3
CONFIDENCE_THRESHOLD=0.7
```

### 4. Services starten

#### Option A: Docker Compose (empfohlen)

```powershell
# Alle Services starten (Ollama + Qdrant + GuardRAG)
docker-compose up -d

# Ollama Modelle pullen
docker exec guardrag-ollama-1 ollama pull qwen2.5:latest
docker exec guardrag-ollama-1 ollama pull granite3.2-vision:2b
```

#### Option B: Lokale Services

```powershell
# 1. Qdrant starten
docker run -p 6333:6333 -p 6334:6334 -v qdrant_storage:/qdrant/storage:z qdrant/qdrant:latest

# 2. Ollama starten (falls nicht installiert)
# Download von https://ollama.ai und installieren
ollama serve
ollama pull qwen2.5:latest

# 3. GuardRAG starten
.venv\Scripts\activate
python main.py
```

### 5. VerfÃ¼gbarkeitsprÃ¼fung

```bash
# Health Check
curl http://localhost:8000/health

# API-Dokumentation
# Swagger UI: http://localhost:8000/docs
# ReDoc: http://localhost:8000/redoc
```

## ğŸ“– API-Nutzung

### Dokument hochladen

```bash
curl -X POST "http://localhost:8000/upload-document" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@document.pdf"
```

**Response:**
```json
{
  "success": true,
  "message": "Document processed successfully",
  "file_id": "1641234567_document.pdf",
  "pages_processed": 15
}
```

### RAG-Abfrage stellen

```bash
curl -X POST "http://localhost:8000/rag-query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Welche Methodik wurde in der Studie verwendet?",
    "max_results": 5
  }'
```

**Response:**
```json
{
  "answer": "Basierend auf den bereitgestellten Dokumenten verwendete die Studie eine quantitative Methodik mit...",
  "confidence": 0.85,
  "processing_time": 2.34,
  "sources": [
    {
      "page_number": 3,
      "score": 0.92,
      "explanation": "Seite 3 enthÃ¤lt Ã¼bereinstimmende Begriffe: methodik, studie",
      "text_preview": "Die Methodik dieser Studie basiert auf..."
    }
  ],
  "warnings": [],
  "guardrail_checks": {
    "input_validation": {
      "result": "accepted",
      "reason": "Wissenschaftliche Begriffe gefunden: methodik, studie",
      "confidence": 0.8
    },
    "output_validation": {
      "result": "approved", 
      "reason": "Alle Validierungen bestanden",
      "confidence": 0.85
    }
  }
}
```

### System-Status abrufen

```bash
curl -X GET "http://localhost:8000/system-status"
```

## ğŸ›¡ï¸ Guardrails - Intelligente Sicherheitssysteme

### ğŸ” Input Guardrails

**Zweck**: Hybrid LLM+Regex Filterung problematischer oder irrelevanter Anfragen

**PrÃ¼fkategorien**:

#### 1. ğŸ’¬ ProfanitÃ¤t & ToxizitÃ¤t
- **Deutsche & englische SchimpfwÃ¶rter**: fuck, scheiÃŸe, arschloch, etc.
- **Diskriminierende Begriffe**: rassistische, sexistische, homophobe Sprache
- **Hasssprache**: Nazi-Begriffe, Fremdenfeindlichkeit
- **Toxische Kommunikationsmuster**: Bedrohungen, Beleidigungen

#### 2. ğŸ”’ PII-Erkennung (PersÃ¶nliche Daten)
- **E-Mail-Adressen**: max.mustermann@beispiel.de
- **Telefonnummern**: +49 123 456789, deutsche und internationale Formate
- **Deutsche Adressen**: MusterstraÃŸe 123, 12345 Berlin
- **Bankdaten**: IBAN, Kreditkartennummern
- **Personennamen**: spaCy-basierte Named Entity Recognition
- **Ausweisnummern**: Deutsche Steuer-ID, Personalausweis

#### 3. âš ï¸ GefÃ¤hrliche Inhalte (mit automatischem Lernen)
- **Sprengstoff-Chemikalien**: Toluol, Schwefel, SalpetersÃ¤ure, TNT, C4
- **Drogen**: CBD, THC, Cannabis, Methamphetamine, Kokain, LSD
- **Waffen**: Pistole, Gewehr, AK47, Munition
- **Illegale AktivitÃ¤ten**: Hacking, Phishing, GeldwÃ¤sche

**ğŸ§  Hybrid-Ansatz**:
1. **Regex-Trigger** erkennen verdÃ¤chtige Begriffe (schnell)
2. **LLM analysiert Kontext** (intelligent): 
   - "Puderzucker fÃ¼r Guggelhupf" â†’ âœ… harmlos (Backen)
   - "Puderzucker + Salz explodieren" â†’ âŒ gefÃ¤hrlich (Sprengstoff)
3. **Automatisches Lernen**: LLM-erkannte Gefahren ohne Regex â†’ Lern-Log

#### 4. ğŸ¢ Konkurrenten-Erkennung
- **Blockierte Anbieter**: OpenAI, ChatGPT, Claude, Gemini, Anthropic
- **Benutzerdefinierte Listen**: Erweiterbar
- **Automatische Blockierung**: Bei ErwÃ¤hnung von Konkurrenzprodukten

#### 5. ğŸ§¹ Text-Sanitisierung
- **PII-Ersetzung**: E-Mails â†’ [EMAIL], Telefon â†’ [PHONE]
- **Overlap-Resolution**: Ãœberlappende Erkennungen bereinigen
- **Struktur-Erhaltung**: Textformat bleibt erhalten

### âœ… Output Guardrails

**Zweck**: QualitÃ¤tssicherung und SicherheitsprÃ¼fung der generierten Antworten

**PrÃ¼fungen**:
- **Faktentreue**: Abgleich mit Quellendokumenten
- **VollstÃ¤ndigkeit**: Angemessene Beantwortung der Frage
- **Halluzinations-Detektion**: Erkennung erfundener Informationen
- **ToxizitÃ¤tsprÃ¼fung**: Sicherstellung sauberer Ausgaben
- **Relevanz-Check**: Passende Antwort zur Frage

### ğŸ“Š Beispiele

#### âœ… Zugelassene Anfragen
```
"Wie funktioniert maschinelles Lernen?"
"CBD Kekse backen - welche Dosierung?"
"Welche Methodik wurde in der Studie verwendet?"
```

#### âŒ Blockierte Anfragen
```
"Du bist so dumm!" (ToxizitÃ¤t)
"Wie stelle ich Sprengstoff her?" (GefÃ¤hrlicher Inhalt)
"Meine E-Mail ist max@test.de" (PII)
"ChatGPT ist besser" (Konkurrent)
```

#### ğŸ§¹ Sanitisierte Ausgaben
```
Input:  "Kontaktiere mich unter max@test.de"
Output: "Kontaktiere mich unter [EMAIL]"
```

## ğŸ”§ Konfiguration & VerfÃ¼gbare Modelle

### Umgebungsvariablen

| Variable | Beschreibung | Default |
|----------|--------------|---------|
| `LLM_ENDPOINT` | Ollama API Endpoint | `http://localhost:11434/v1` |
| `LLM_API_KEY` | API Key fÃ¼r LLM | `ollama` |
| `LLM_MODEL` | Modell fÃ¼r Generation | `qwen2.5:latest` |
| `COLPALI_MODEL` | COLPALI Modell | `vidore/colqwen2.5-v0.2` |
| `QDRANT_HOST` | Qdrant Server Host | `localhost` |
| `QDRANT_PORT` | Qdrant Server Port | `6333` |
| `ENABLE_INPUT_GUARDRAILS` | Input-Validierung aktivieren | `true` |
| `ENABLE_OUTPUT_GUARDRAILS` | Output-Validierung aktivieren | `true` |
| `TOXICITY_THRESHOLD` | Schwellwert fÃ¼r ToxizitÃ¤t | `0.3` |
| `CONFIDENCE_THRESHOLD` | Mindestvertrauen | `0.7` |

### ğŸ¤– UnterstÃ¼tzte LLM-Modelle

Das System unterstÃ¼tzt **alle OpenAI-kompatiblen API-Endpunkte**:

#### ğŸ  Lokale Modelle (Ollama) z. B.
- **`qwen2.5:latest`** â­ - Empfohlenes Standardmodell (Allzweck)
- **`qwen3:latest`** - Neueste Qwen-Version
- **`granite3.3:8b`** - Ausgewogenes Allzweck-Modell
- **`google/gemma3:latest`** - Google's Gemma-Modell
- **Alle weiteren Ollama-Modelle** - VollstÃ¤ndige KompatibilitÃ¤t

#### â˜ï¸ Cloud-APIs (OpenAI-kompatibel)
- **OpenAI**: GPT-4, GPT-3.5-turbo, GPT-4-turbo
- **Anthropic**: Claude-3.5-Sonnet, Claude-3-Haiku (via kompatible APIs)
- **Groq**: Llama-3, Mixtral, Gemma (schnelle Inferenz)
- **Together AI**: Llama-2/3, Code Llama, Mistral
- **Perplexity**: Llama-3, Mixtral-8x7B
- **OpenRouter**: Zugang zu 100+ Modellen
- **Azure OpenAI**: Enterprise-GPT-Modelle
- **AWS Bedrock**: Claude, Llama Ã¼ber OpenAI-Proxy

#### ğŸ”§ Konfiguration fÃ¼r verschiedene Anbieter

```bash
# Lokale Ollama-Installation
LLM_ENDPOINT=http://localhost:11434/v1
LLM_API_KEY=ollama
LLM_MODEL=qwen2.5:latest

# OpenAI
LLM_ENDPOINT=https://api.openai.com/v1
LLM_API_KEY=sk-your-openai-key
LLM_MODEL=gpt-4

# Groq (schnelle Inferenz)
LLM_ENDPOINT=https://api.groq.com/openai/v1
LLM_API_KEY=gsk_your-groq-key
LLM_MODEL=llama-3.1-70b-versatile

# Together AI
LLM_ENDPOINT=https://api.together.xyz/v1
LLM_API_KEY=your-together-key
LLM_MODEL=meta-llama/Llama-3-70b-chat-hf

# OpenRouter (Multi-Provider)
LLM_ENDPOINT=https://openrouter.ai/api/v1
LLM_API_KEY=sk-or-your-openrouter-key
LLM_MODEL=anthropic/claude-3.5-sonnet

# Lokale vLLM-Installation
LLM_ENDPOINT=http://localhost:8000/v1
LLM_API_KEY=token-abc123
LLM_MODEL=microsoft/DialoGPT-medium
```

Das System funktioniert mit **jedem OpenAI-kompatiblen Endpunkt** - einfach Endpoint, API-Key und Modellname konfigurieren!

### ğŸ“‚ Projektstruktur

```
GuardRAG/
â”œâ”€â”€ src/                           # ğŸ¯ Kernkomponenten
â”‚   â”œâ”€â”€ modern_guardrails.py       # ğŸ›¡ï¸ Hybrid LLM+Regex Guardrails
â”‚   â”œâ”€â”€ colpali_integration.py     # ğŸ” COLPALI + Qdrant Integration
â”‚   â”œâ”€â”€ qdrant_integration.py      # ğŸ“Š Vektor-Datenbank
â”‚   â”œâ”€â”€ input_guardrail.py         # ğŸš« Eingabevalidierung
â”‚   â”œâ”€â”€ output_guardrail.py        # âœ… Ausgabevalidierung
â”‚   â””â”€â”€ rag_agent.py               # ğŸ¤– Haupt-RAG-Agent
â”œâ”€â”€ mcp_fileconverter/             # ğŸ“ PDF-Konvertierung
â”‚   â””â”€â”€ file2pdf.py               # ğŸ”„ Datei-zu-PDF-Konverter
â”œâ”€â”€ tests/                         # ğŸ§ª Test-Suite (optional)
â”‚   â””â”€â”€ (weitere Test-Dateien)     # ï¿½ ErgÃ¤nzende Tests
â”œâ”€â”€ main.py                        # ğŸš€ FastAPI-Anwendung
â”œâ”€â”€ test_hybrid_guardrails.py     # ï¿½ï¸ Guardrails-Tests
â”œâ”€â”€ test_complete_system.py       # ğŸ§ª System-Tests
â”œâ”€â”€ tasks.py                      # âš™ï¸ Development Tasks
â”œâ”€â”€ docker-compose.yml            # ğŸ³ Multi-Service Setup
â”œâ”€â”€ pyproject.toml                # âš™ï¸ Projekt-Konfiguration
â”œâ”€â”€ .env.example                  # ğŸ“ Umgebungsvorlage
â””â”€â”€ uploads/                      # ğŸ“ Upload-Verzeichnis
```

## ğŸ” COLPALI-Integration

GuardRAG nutzt COLPALI (Collaborative Learning for Vision-Language Models) fÃ¼r effizienten visuellen Dokumentenabruf:

### Funktionsweise

1. **PDF-Verarbeitung**: Konvertierung zu hochauflÃ¶senden Bildern (200 DPI)
2. **Embedding-Generierung**: COLPALI erstellt Multi-Vector-Embeddings
3. **Visuelle Suche**: SimilaritÃ¤tsberechnung zwischen Query und Dokumentenseiten
4. **Ranking**: Relevanz-Score-basierte Sortierung

### Vorteile

- **Layout-Bewusstsein**: Erkennt Tabellen, Diagramme, Strukturen
- **OCR-frei**: Keine fehleranfÃ¤llige Texterkennung nÃ¶tig
- **Multimodal**: Text und visuelle Elemente gemeinsam
- **Effizienz**: Schnelle Suche in groÃŸen Dokumentensammlungen

## ğŸ§ª Testing & CLI-Tester

### ğŸ–¥ï¸ Test-Skripte

GuardRAG enthÃ¤lt verschiedene Test-Skripte fÃ¼r die Funktionsvalidierung:

```bash
# Hybrid Guardrails System testen
python test_hybrid_guardrails.py

# Komplettes System testen
python test_complete_system.py

# Development Tasks ausfÃ¼hren
python tasks.py help
```

**ğŸ¯ Test-Funktionen**:
- **ï¿½ï¸ Guardrails-Tests**: Hybrid LLM+Regex Validation
- **ğŸ” System-Tests**: VollstÃ¤ndige Integration
- **ğŸ§ª Unit-Tests**: Einzelkomponenten-Validierung
- **ğŸ“Š Development Tasks**: Code-QualitÃ¤t und Automatisierung

**ğŸ›ï¸ Available Test Commands**:
```bash
# Hybrid Guardrails testen
python test_hybrid_guardrails.py

# Komplettes System validieren  
python test_complete_system.py

# Development Tasks
python tasks.py dev-setup      # Entwicklungsumgebung einrichten
python tasks.py test-unit      # Unit Tests ausfÃ¼hren
python tasks.py format         # Code formatieren
python tasks.py lint          # Code-QualitÃ¤t prÃ¼fen
python tasks.py help          # Alle verfÃ¼gbaren Tasks
```

**ğŸ“‹ Test-Ausgabe-Format**:
```
ï¿½ï¸ GUARDRAILS TEST RESULTS
==================================================
âœ… Input Validation: PASSED/FAILED
ğŸ§¹ Sanitization: '[EMAIL] entfernt' 
ï¿½ Detection Categories:
   â€¢ ProfanitÃ¤t: 0 found
   â€¢ PII: 1 detected
   â€¢ Dangerous Content: 0 found
   â€¢ Toxicity: 0 found
ğŸ¯ Confidence: 0.95
â±ï¸ Processing Time: 0.12s
```

### ğŸ§ª Automated Test Suite

```powershell
# Test-Skripte ausfÃ¼hren
python test_hybrid_guardrails.py    # Guardrails-System testen
python test_complete_system.py      # Komplette Integration

# Development Tasks
python tasks.py test-unit            # Unit Tests
python tasks.py dev-setup           # Entwicklungsumgebung

# Direkte Test-Skripte
python test_hybrid_guardrails.py    # Guardrails-System testen
python test_complete_system.py      # Komplette Integration
```

**ğŸ“ VerfÃ¼gbare Test-Dateien**:
- **`test_hybrid_guardrails.py`** - Hybrid LLM+Regex Guardrails-Tests
- **`test_complete_system.py`** - Komplette System-Integration-Tests
- **`tasks.py`** - Entwicklungsaufgaben-Manager und Test-Runner

### ğŸ“Š Test-Output

Die Test-Skripte liefern strukturierte Ausgaben zur Validierung der Guardrails-FunktionalitÃ¤t.

## ğŸ“Š Monitoring

### Health Check

```bash
curl -X GET "http://localhost:8000/health"
```

### Logs

Logs werden in strukturiertem Format ausgegeben:
```
2025-01-10 15:30:45 - guardrag.main - INFO - GuardRAG application started successfully
2025-01-10 15:31:02 - guardrag.rag_agent - INFO - Processing query: "Welche Methodik wurde verwendet?"
2025-01-10 15:31:03 - guardrag.input_guardrail - INFO - Input validation passed
2025-01-10 15:31:05 - guardrag.colpali - INFO - Retrieved 5 relevant pages
2025-01-10 15:31:07 - guardrag.output_guardrail - INFO - Output validation approved
```

## ğŸ› ï¸ Entwicklung & Code-QualitÃ¤t

### Development Tasks

```powershell
# Entwicklungsumgebung einrichten
python tasks.py dev-setup

# Code formatieren
python tasks.py format

# Code prÃ¼fen  
python tasks.py lint

# Dependencies installieren
python tasks.py install-dev

# Server starten
python tasks.py start

# Alle verfÃ¼gbaren Tasks anzeigen
python tasks.py help
```

### ğŸ”§ Konfiguration fÃ¼r verschiedene Umgebungen

#### Qdrant-Konfiguration
```python
# Lokale Qdrant-Instanz
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Qdrant Cloud
QDRANT_URL=https://your-cluster.qdrant.tech
QDRANT_API_KEY=your-api-key
```

#### COLPALI-Konfiguration
Das System nutzt standardmÃ¤ÃŸig das `vidore/colqwen2.5-v0.2` Modell fÃ¼r visuelle Dokumentenanalyse. Bei Memory-Problemen kann ein kleineres Modell verwendet werden:

```bash
# Kleineres COLPALI-Modell bei Memory-Problemen
export COLPALI_MODEL=vidore/colSmol-256M
```

## ğŸš¨ Troubleshooting & FAQ

### HÃ¤ufige Probleme

#### 1. **CUDA Out of Memory**
```bash
# Kleineres COLPALI-Modell verwenden
export COLPALI_MODEL=vidore/colSmol-256M

# Docker Memory Limits erhÃ¶hen
docker-compose up --scale guardrag=1 --memory=8g
```

#### 2. **Ollama Connection Error**
```bash
# Ollama-Service prÃ¼fen
ollama list
ollama serve

# API-VerfÃ¼gbarkeit testen
curl http://localhost:11434/api/tags
```

#### 3. **Qdrant Connection Failed**
```bash
# PrÃ¼fe ob Qdrant lÃ¤uft
curl http://localhost:6333/collections

# Qdrant in Docker starten
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant:latest
```

#### 4. **PDF Conversion Fehler**
```bash
# LibreOffice installieren (fÃ¼r Office-Dateien)
# WeasyPrint installieren (fÃ¼r HTML)
uv pip install weasyprint
```

#### 5. **COLPALI Model Download**
```bash
# Manuell Model herunterladen
python -c "from colpali_engine.models import ColQwen2; ColQwen2.from_pretrained('vidore/colqwen2.5-v0.2')"
```

#### 6. **Test-Skripte starten nicht**
```bash
# PrÃ¼fe verfÃ¼gbare Test-Dateien
python test_hybrid_guardrails.py
python test_complete_system.py

# PrÃ¼fe moderne_guardrails Module-Import
python -c "from src.modern_guardrails import create_guardrails_validator"

# spaCy deutsche Modelle installieren
python -m spacy download de_core_news_lg
python -m spacy download de_core_news_sm
```

### Debug-Modus

```bash
# Verbose Logging aktivieren
export UVICORN_LOG_LEVEL=debug
python main.py

# Guardrails Learning-Logs Ã¼berwachen
tail -f guardrails_learning.jsonl
```

### Performance-Optimierung

```bash
# GPU-Nutzung prÃ¼fen
nvidia-smi

# Memory-Usage Ã¼berwachen
htop

# Qdrant Performance tuning
curl -X PUT "http://localhost:6333/collections/documents/index" \
  -H "Content-Type: application/json" \
  -d '{"field_name": "vector", "field_schema": "Float"}'
```

## ğŸ“„ Lizenz

Dieses Projekt steht unter der **GNU Affero General Public License v3.0 (AGPL-3.0)**.

### Was bedeutet das?

- âœ… **Freie Nutzung**: Kostenlose Nutzung fÃ¼r alle Zwecke
- âœ… **Quellcode-Zugang**: VollstÃ¤ndiger Quellcode verfÃ¼gbar
- âœ… **Modifikationen erlaubt**: Anpassungen und Erweiterungen mÃ¶glich
- âœ… **Weitergabe erlaubt**: Redistribution unter gleicher Lizenz

### Copyleft-Bedingungen

- ğŸ“¤ **Quellcode-Pflicht**: Bei Weitergabe muss Quellcode mitgeliefert werden
- ğŸŒ **Network-Copyleft**: Auch bei Online-Services muss Quellcode verfÃ¼gbar sein
- ï¿½ **Gleiche Lizenz**: Abgeleitete Werke mÃ¼ssen unter AGPL-3.0 stehen

Siehe [LICENSE.md](LICENSE.md) fÃ¼r vollstÃ¤ndige Details.

## ğŸ™ Danksagungen

- **[COLPALI](https://github.com/illuin-tech/colpali)** fÃ¼r das exzellente Vision-Language-Retrieval-Framework
- **[PydanticAI](https://ai.pydantic.dev/)** fÃ¼r die strukturierte LLM-Integration
- **[FastAPI](https://fastapi.tiangolo.com/)** fÃ¼r das moderne Web-Framework
- **[Ollama](https://ollama.com/)** fÃ¼r lokale LLM-Inferenz
- **[Qdrant](https://qdrant.tech/)** fÃ¼r die hochperformante Vektordatenbank
- **[spaCy](https://spacy.io/)** fÃ¼r Named Entity Recognition
- **[OpenAI](https://openai.com/)** fÃ¼r die API-KompatibilitÃ¤t


### ğŸ” Weitere Ressourcen

- **API-Dokumentation**: http://localhost:8000/docs (Swagger UI)
- **Alternative Docs**: http://localhost:8000/redoc (ReDoc)
- **Health Check**: http://localhost:8000/health
- **System Status**: http://localhost:8000/system-status

---

ğŸ›¡ï¸ **GuardRAG** - Sichere, intelligente und lernfÃ¤hige Dokumentenanalyse mit modernsten AI-Guardrails!